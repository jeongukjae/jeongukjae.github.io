---
layout: post
title: ğŸ“• CS224n Lecture 18 Constituency Parsing and Tree Recursive Neural Networks
tags:
  - nlp
  - cs224n
  - machine learning
---

18ê°•ì´ê³  ê°•ì˜ ì „ì²´ê°€ ë‹¤ ëë‚˜ê¸°ê¹Œì§€ ì´ ê°•ì˜ë¥¼ ì œì™¸í•˜ê³  2ê°•ì •ë„ë§Œ ë‚¨ì•˜ë‹¤.

#### Last Minute Project Tips

ì´ê±´ íŒŒì´ë„ í”„ë¡œì íŠ¸ íŒì¸ë°, ëŠë¦¬ê³  ì•„ë¬´ê²ƒë„ ë™ì‘ì•ˆí•˜ë©´ ì²˜ìŒìœ¼ë¡œ ê·¸ëƒ¥ ë§˜í¸íˆ ëŒì•„ê°€ì„œ ë‹¤ì‹œ í•´ë³´ëŠ” ê²ƒì´ ì¢‹ë‹¤ê³ . íŒ¨ë‹‰ì¸ ìƒí™©ì¼í…Œë‹ˆê¹Œ. ë””ë²„ê¹…ì„ ìœ„í•´ ë§¤ìš° ì‘ì€ ë„¤íŠ¸ì›Œí¬ë‘ ë°ì´í„°ë¥¼ ë„£ì–´ë³´ê¸°ë„ í•˜ê³ , ì˜ ë™ì‘í•˜ë©´ ëª¨ë¸ ì‚¬ì´ì¦ˆë¥¼ í‚¤ì›Œë³´ê¸°ë„ í•˜ë¼ê³  í•œë‹¤.

## Motivation: Compositionality and Recursion

* semantic ì •ë³´ë¥¼ ìš°ë¦¬ê°€ ì˜ ê°€ì ¸ê°ˆ ìˆ˜ ìˆì„ê¹Œ?
* word embeddingë§Œìœ¼ë¡œ ì¶©ë¶„í• ê¹Œ?
* ë§Œì•½ ì˜ ê°€ì ¸ê°ˆ ìˆ˜ ìˆë‹¤ê³  í•´ë„, ì •ë§ í° phraseì— ëŒ€í•´ì„œëŠ”?

ìœ„ì˜ ë¬¸ì œ ë•Œë¬¸ì— compositionalityë¥¼ ìƒê°í•˜ê²Œ ë˜ì—ˆê³ , ë‹¨ì–´, êµ¬ë“¤ì˜ semantic compositionì„ êµ¬ì„±í•˜ìëŠ” ì•„ì´ë””ì–´ê°€ ë‚˜ì™”ë‹¤.

{% include image.html url="/images/cs224n/18-1.png" description="ì•½ê°„ ìš”ëŸ° composition??" %}

ê·¸ëŸ¼ tree í˜•íƒœë¡œ êµ¬ì„±í•˜ê¸° ìœ„í•´ì„œ recursiveí•œì§€ ë¬¼ì–´ë³¸ë‹¤ë©´ ë…¼ìŸì´ ìˆì„ ìˆ˜ ìˆê² ì§€ë§Œ, language ìì²´ë¥¼ í‘œí˜„í•˜ëŠ”ë° ì—„ì²­ ìì—°ìŠ¤ëŸ½ë‹¤ê³ .

{% include image.html url="/images/cs224n/18-2.png" description="ì•”íŠ¼ ìì—°ìŠ¤ëŸ¬ì›€" %}

## Structure prediction with simple Tree RNN: Parsing

vector spaceì— word vectorë¥¼ ë¿Œë ¤ë†“ëŠ”ë°, ê·¸ëŸ¼ êµ¬ë“¤ì€ ì–´ë–»ê²Œ í•´ì•¼í•˜ë‚˜?? -> ê·¸ëƒ¥ ë°”ë¡œ ê°™ì€ vector spaceì— ë„£ì–´ë²„ë¦¬ì. ê·¸ëŸ¼ ì–´ë–»ê²Œ phraseì˜ embeddingì„ ê²°ì •í• ê¹Œ??

1. ë‹¨ì–´ì˜ ì˜ë¯¸ë“¤ê³¼
2. ê·¸ë“¤ì„ combineí•˜ëŠ” ê·œì¹™ì„ ë§Œë“¤ì–´ì„œ!

{% include image.html url="/images/cs224n/18-3.png" description="ì´ë ‡ê²Œ ì´ë ‡ê²Œ ì˜ ë½€ê¹Œë½€ê¹Œ" %}

ìœ„ì˜ ê²½ìš°ëŠ” recursiveí•œ ê²½ìš°ì´ê³ , ì¼ë°˜ì ì¸ rnnì„ í†µí•´ì„œë„ ê²°ê³¼ëŠ” ë‹¤ë¥´ê² ì§€ë§Œ êµ¬í•´ë³¼ ìˆ˜ ìˆë‹¤. í•˜ì§€ë§Œ recursiveí•œ êµ¬ì¡°ëŠ” tree structureë¥¼ êµ¬ì„±í•´ì£¼ì–´ì•¼ í•œë‹¤ëŠ” ì–´ë ¤ì›€ì´ ë”°ë¥´ê³ , rnnì„ í†µí•œ êµ¬ì¡°ëŠ” phraseë¥¼ prefix contextì—†ì´ ì¡ì•„ë‚´ì§€ë„ ëª»í•˜ê³ , ë§ˆì§€ë§‰ ê²°ê³¼ vectorê°€ ë§ˆì§€ë§‰ ë‹¨ì–´ì— ì¢Œìš°ëœë‹¤ëŠ” ë‹¨ì ì´ ìˆë‹¤.

ê·¸ëŸ¼ NNì— ì–´ë–»ê²Œ structure predictionì„ í•  ìˆ˜ ìˆì„ê¹Œ? ì´ë ‡ê²Œ childrenì„ ë„£ê³  semantic representationì„ ë½‘ì•„ë‚´ê³ , ì–¼ë§ˆë‚˜ plausibleí•œì§€(ì–¼ë§ˆë‚˜ Networkê°€ ì´ ë…¸ë“œë¥¼ í™•ì‹ í•˜ëŠ”ì§€ ì •ë„..?)ë„ ë½‘ì•„ë‚¸ë‹¤. ê·¸ëŸ° NNì„ ëª¨ë“  children ëŒ€ìƒìœ¼ë¡œ ì­‰ ëŒë¦°ë‹¤ìŒì— ê·¸ ìœ„ì˜ ì¸µì—ì„œë„ ë˜ ëŒë¦¬ê³ , ë˜ ëŒë¦¬ê³  í•œë‹¤ê³  í•˜ëŠ”ë°, ë‚´ê°€ ë‹¤ì‹œ ì´ ê¸€ì„ ë´ë„ ì´í•´ ëª»í•  ë“¯ í•˜ë‹ˆ ì•„ë˜ ì‚¬ì§„ì„ ë³´ì.

{% include image.html url="/images/cs224n/18-4.png" description="ì´ë ‡ê²Œ ì´ë ‡ê²Œ ì˜" %}

{% include image.html url="/images/cs224n/18-5.png" description="ì´ê±¸ ì˜ childrenì„ ë„£ì–´ì„œ" %}

{% include image.html url="/images/cs224n/18-6.png" description="ì˜ ìš”ë ‡ê²Œ ìš”ë ‡ê²Œ" %}

{% include image.html url="/images/cs224n/18-7.png" description="ë¿…!" %}

## Backpropagation through Structure

general backpropê³¼ í¬ê²Œ ë‹¤ë¥¼ ê²ƒì€ ì—†ë‹¤. ì›ì¹™ì ìœ¼ë¡œëŠ” ê°™ë‹¤. [Goller & KuÌˆchler (1996)](https://www.semanticscholar.org/paper/Learning-task-dependent-distributed-representations-Goller-Kuchler/794e6ed81d21f1bf32a0fd3be05c44c1fa362688)ì— ì˜í•´ ì†Œê°œë˜ì—ˆë‹¤.

forward propì¼ ë•Œ, children $$c_1$$, $$c_2$$ê°€ ìˆë‹¤ê³  í•˜ì. ê±°ê¸°ì„œ parent $$p$$ë¥¼ ë½‘ì•„ë‚´ê¸° ìœ„í•´ $$p = \tanh (W \pmatrix {c_1 \\ c_2} + b)$$ì™€ ê°™ì€ ì—°ì‚°ì„ í•œë‹¤. ê·¸ëŸ¼ backward propì€ ë°˜ëŒ€ë¡œ ê°ê°ì˜ ë…¸ë“œë³„ë¡œ ì—°ì‚°ì„ í•´ì¤€ë‹¤. ì´ëŸ° Simple TreeRNNì— ëŒ€í•´ì„œ ì•„ë˜ì™€ ê°™ì€ ì ì„ ìƒê°í•´ë³¼ ìˆ˜ ìˆë‹¤.

* ìƒê°ë³´ë‹¤ ê²°ê³¼ëŠ” ë‚˜ì˜ì§€ ì•Šê³ 
* ì¢€ phraseë¥¼ ì¡ì•„ë‚¼ ìˆ˜ëŠ” ìˆëŠ”ë°, more higher order composition, more complexí•œ long sentenceë¥¼ íŒŒì‹±í•˜ëŠ”ë° ì–´ë ¤ì›€ì´ ìˆë‹¤.
* input wordë“¤ ì‚¬ì´ì˜ interactionì€ í•˜ë‚˜ë„ ì—†ë‹¤.
* composition functionì´ ë‹¤ ë˜‘ê°™ë‹¤

## More complex TreeRNN units

ë‘ë²ˆì§¸ë¡œ Syntactically-United RNNì´ ìˆëŠ”ë°, [Socher, Bauer, Manning, Ng 2013](https://www.aclweb.org/anthology/P13-1045)ì„ ì‚´í´ë³´ì.

ê¸°ë³¸ì ì¸ syntactic structureë¥¼ ìœ„í•´ì„œëŠ” symbolic Context-Free Grammar (CFG) backboneì´ ì¢‹ì•˜ë‹¤ê³  í•œë‹¤. ê·¸ë¦¬ê³  discrete syntactic categoryë¥¼ ì‚¬ìš©í–ˆë‹¤ê³  í•˜ê³ , ë‹¤ë¥¸ syntactic environmentì—ì„œëŠ” ë‹¤ë¥¸ composition matrixë¥¼ ì‚¬ìš©í•˜ê²Œ í•´ì£¼ëŠ” ê²ƒì´ í›¨ì”¬ ì¢‹ì€ ê²°ê³¼ë¥¼ ë‚´ì—ˆë‹¤ê³  í•œë‹¤. ê·¸ë¦¬ê³  ë” ì¢‹ì€ semanticì˜ ê²°ê³¼ë¥¼ ë³¼ ìˆ˜ ìˆì—ˆë‹¤ê³ .

ì•„ì§ ìœ„ì˜ ë…¼ë¬¸ì„ ì½ì–´ë³´ì§€ ì•Šì•„ì„œ ìì„¸í•œ ë‚´ìš©ì„ ëª¨ë¥´ì§€ë§Œ, ê°•ì˜ì˜ ë‚´ìš©ëŒ€ë¡œ ì¨ë³´ìë©´, Compositional Vector Grammarë¥¼ ì´ìš©í•˜ëŠ” ê²ƒì˜ ë‹¨ì ì´ ì¼ë‹¨ ë¬¸ì œì ì´ ì†ë„ê°€ ëŠë¦¬ë‹¤ê³  í•œë‹¤. Beam Search ê³¼ì •ì—ì„œ matrix-vector productë¥¼ í•˜ë‹ˆ ì—°ì‚°ëŸ‰ì´ ë§ì•„ì§ˆ ìˆ˜ ë°–ì— ì—†ë‹¤ê³ . ê·¸ë˜ì„œ subset of treeë¥¼ ë¨¼ì € ê³„ì‚°í•´ë³´ê³  very unlikely candidatesë¥¼ ë¯¸ë¦¬ ì—†ì• ëŠ” ë°©ë²•(PCFG)ì„ ì‚¬ìš©í–ˆë‹¤ê³  í•œë‹¤. ê·¸ë˜ì„œ CVG = PCFG + TreeRNN

{% include image.html url="/images/cs224n/18-8.png" description="ë‚˜ì¤‘ì„ ìœ„í•´ ì €ì¥! (CVG = Compositional Vector Grammerì¸ë“¯..?)" %}

45:11 ê¹Œì§€ ë“¤ìŒ

## Other uses of tree-recursive neural nets

## Institute for Human-Centered Artificial Intelligence
