---
layout: post
title: "ğŸ“• CS224n Lecture 17 The Natural Language Decathlon: Multitask Learning as Question Answering"
tags:
  - cs224n
---

Richard Socherë¼ëŠ” Saleforceì˜ Chief Scientistê°€ ê²ŒìŠ¤íŠ¸ë¡œ ë‚˜ì™€ ê°•ì˜ë¥¼ í•œë‹¤ê³  í•œë‹¤.

* [ìŠ¬ë¼ì´ë“œ](http://web.stanford.edu/class/cs224n/slides/cs224n-2019-lecture17-multitask.pdf)
* [ì˜ìƒ](https://www.youtube.com/watch?v=M8dsZsEtEsg)
* [decaNLP paper (The Natural Language Decathlon: Multitask Learning as Question Answering)](https://arxiv.org/pdf/1806.08730.pdf)

ê°•ì˜ëŠ” ì „ì²´ì ìœ¼ë¡œ multi-task learningì— ëŒ€í•œ ë‚´ìš©ì¸ë°, single-taskì˜ í•œê³„ì— ëŒ€í•´ì„œ ë¨¼ì € ì•Œì•„ë³´ì. ìµœê·¼ì— dataset, task, model, metricì— ëŒ€í•œ ì—„ì²­ë‚œ ë°œì „ì´ ìˆì—ˆì§€ë§Œ, ì˜ˆì „ì—ëŠ” ìƒˆë¡œìš´ ëª¨ë¸ì€ ê±°ì˜ randomí•œ ìƒíƒœì—ì„œ ìƒˆë¡œ ì‹œì‘í•˜ê±°ë‚˜ ì¼ë¶€ë§Œ pre-trainëœ ìƒíƒœì—ì„œ ì‹œì‘í•´ì•¼í–ˆë‹¤. í•˜ì§€ë§Œ ì‹œê°„ì´ ì§€ë‚˜ë©´ì„œ word2vec, GloVe, CoVe, ELMo, BERTì²˜ëŸ¼ ë” ë§ì€ ë¶€ë¶„ì„ pretrainí•´ì„œ ëª¨ë¸ì„ ìƒˆë¡œ êµ¬ì„±í•  ë•Œ ë” ì¢‹ì€ ê²°ê³¼ë¥¼ ë‚´ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆì—ˆë‹¤.

ê·¸ëŸ¼ ì „ì²´ë¥¼ ì™œ pretrained modelì„ ì‚¬ìš©í•˜ì§€ ì•Šì„ê¹Œ?

{% include image.html url="/images/cs224n/17-1.png" %}

ê·¸ëŸ¼ ë§ì€ íƒœìŠ¤í¬ë¥¼ í•˜ë‚˜ì˜ NLP í”„ë ˆì„ì›Œí¬ë¡œ ë¬¶ì„ ìˆ˜ëŠ” ì—†ì„ê¹Œ?

{% include image.html url="/images/cs224n/17-2.png" %}

ê·¸ëŸ¼ í¬ê²Œ 3ê°œì˜ ë¶„ë¥˜ë¡œ NLP íƒœìŠ¤í¬ë“¤ì„ ë‚˜ëˆ„ì–´ë³´ì

* sequence tagging : NER, aspect specific sentiment
* text classification : dialogue state tracking, sentiment classification
* seq2seq : MT, summarization, QA

ê²°ë¡ ì€ salesforceì—ì„œ ê°œë°œí•˜ê³  ìˆëŠ” [decaNLP](https://github.com/salesforce/decaNLP)ì— ëŒ€í•œ ì•½ê°„ì˜ í™ë³´ê°€ ë“¤ì–´ê°€ê¸°ë„ í•˜ëŠ” ê²ƒ ê°™ì§€ë§Œ, ì–´ì¨Œë“  ì´ëŸ° multitask Learningì„ ëª©í‘œë¡œ í•˜ê³  ê°œë°œí•œ ì‹œìŠ¤í…œì´ë¼ê³  í•œë‹¤. decaNLPëŠ” task-specificí•œ moduleì´ë‚˜ parameterê°€ ì—†ë‹¤ê³  í•œë‹¤. í•˜ì§€ë§Œ ì—¬ëŸ¬ê°œì˜ ë‹¤ë¥¸ íƒœìŠ¤í¬ë¥¼ ìˆ˜í–‰í•˜ê¸° ìœ„í•´ ì¡°ì •ì´ ê°€ëŠ¥í•˜ë‹¤ê³  í•œë‹¤. ë³´ì§€ëª»í•œ íƒœìŠ¤í¬ì— ëŒ€í•´ì„œ ëŒ€ì‘í•˜ê³  ì‹¶ì—ˆë‹¤ê³ .

{% include image.html url="/images/cs224n/17-3.png" %}

ê·¸ë¦¬ê³  multitask QAì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ëŠ”ë° ì™„ì „ ì¬ë°Œì–´ë³´ì¸ë‹¤. fixed GloVe + character n-gram embeddingìœ¼ë¡œ linear layer ê±°ì¹œ í›„ì— Shared BiLSTM + skip connectionìœ¼ë¡œ ì—°ê²°í•œê±° ê±°ì¹˜ê³  attention summationí•´ì£¼ëŠ” ë¶€ë¶„ì´ ìˆëŠ”ë° ì´ ë¶€ë¶„ ì œëŒ€ë¡œ ì´í•´ëª»í–ˆë‹¤. ì™œ ê·¸ë ‡ê²Œ í•˜ëŠ”ì§€..? ì•”íŠ¼ ì„œë¡œ attentionì„ ì˜ ì„ì–´ì£¼ê³  ë‚˜ì„œ ì°¨ì› ì¶•ì†Œë¥¼ ìœ„í•´ ë˜ BiLSTMì„ ê±°ì¹œ í›„ Transformer Layerë¥¼ ê±°ì¹œë‹¤. ê·¸ë¦¬ê³  Transformer layer ì´í›„ë¡œ ì œëŒ€ë¡œ ì´í•´ ëª»í•¨..

{% include image.html url="/images/cs224n/17-4.png" %}

íƒœìŠ¤í¬ë³„ë¡œ ë°ì´í„°ì…‹ - Metricì€ ì´ë ‡ê²Œ ì‚¬ìš©í–ˆë‹¤ê³  í•œë‹¤.

ê·¸ ë‹¤ìŒì—ëŠ” multitask learningì„ ìœ„í•œ training strategyë¥¼ ì„¤ëª…í•´ì¤€ë‹¤. ì²«ë²ˆì§¸ëŠ” fully joint.

{% include image.html url="/images/cs224n/17-5.png" %}

> The first strategy we consider is fully joint. In this strategy, batches are sampled round-robin from all tasks in a fixed order from the start of training to the end. This strategy performed well on tasks that required fewer iterations to converge during single-task training (see Table 3), but the model struggles to reach single-task performance for several other tasks. In fact, we found a correlation between the performance gap between single and multitasking settings of any given task and number of iterations required for convergence for that task in the single-task setting.

ê°•ì˜ ì„¤ëª…ì„ ì˜ ì´í•´í•˜ì§€ ëª»í•˜ê³˜ì–´ì„œ í•´ë‹¹ ë…¼ë¬¸ì„ ì°¾ì•„ë³´ì•˜ë‹¤. curriculum learning[^bengio]ì„ ìœ„ì²˜ëŸ¼ ë…¼ë¬¸ì—ì„œ ì„¤ëª…í•˜ëŠ”ë°, batchë¥¼ samplingí•  ë•Œ, fixed orderë¡œ ê³„ì† RRë¡œ ëŒë©´ì„œ ìˆ˜ì§‘í•˜ëŠ” ê²ƒì´ë¼ê³  í•œë‹¤. ì—„ì²­ ë§ì´ ëŒì•„ê°€ convergeë˜ëŠ” íƒœìŠ¤í¬ë“¤ì€ ì˜ ë™ì‘í•˜ì§€ ì•ŠëŠ”ë‹¤ê³ . ê·¸ë˜ì„œ anti-curriculum learningì„ ì‹œë„í•´ë³´ì•˜ë‹¤ê³  í•˜ëŠ”ë°, ì´ê±°ëŠ” phaseë¥¼ ë‘ê°œë¡œ ë‚˜ëˆˆ ë‹¤ìŒì— ì²«ë²ˆì§¸ëŠ” jointlyí•˜ê²Œ í•™ìŠµí•˜ê³  ë³´í†µ ì´ë“¤ì´ ë” ì–´ë ¤ìš´ ê²ƒë“¤ì´ë¼ê³  í•œë‹¤. ë‘ë²ˆì§¸ í˜ì´ì¦ˆëŠ” fully jointlyë¡œ í•™ìŠµí•œë‹¤.

{% include image.html url="/images/cs224n/17-6.png" %}

ë¹¨ê°•ì´ first phaseì´ê³ , íŒŒë‘ì´ ê·¸ ë‚˜ë¨¸ì§€ì´ë‹¤. Reddishí•œ ë¶€ë¶„ì´ ì–´ë µê³  ë°˜ëŒ€ìª½ì´ ì‰½ë‹¤ê³ .

[^bengio]: [Y. Bengio, J. Louradour, R. Collobert, and J. Weston. Curriculum learning. In ICML, 2009.](https://ronan.collobert.com/pub/matos/2009_curriculum_icml.pdf) ë‚˜ì¤‘ì— ê¼­ ë³´ì.. ì´í•´ëŠ” í•´ì•¼ì§€..

ì•”íŠ¼ ê·¸ ê²°ê³¼ì— ëŒ€í•´ì„œ ì—´ì‹¬íˆ ë§í•˜ë‹¤ê°€ ëë‚´ëŠ”ë°, Related Workë¥¼ ë” ë§ì´ ì½ì–´ë³´ì•„ì•¼ ì• ë¶€ë¶„ë„ ì˜ ì´í•´í•  ë“¯ ì‹¶ë‹¤

{% include image.html url="/images/cs224n/17-7.png" %}

ìœ„ ëª©ë¡ì„ ì½ì–´ë³´ì..
