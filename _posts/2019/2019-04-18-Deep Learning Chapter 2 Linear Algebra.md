---
layout: post
title: "ğŸ“— Deep Learning Chapter 2 Linear Algebra"
tags:
  - book
---

Ian Goodfellowì˜ [Deep Learning](http://www.deeplearningbook.org) ì±…ì„ ë³´ê¸° ì‹œì‘í–ˆë‹¤. í•´ë‹¹ ì±…ì— ëŒ€í•´ ì¶”ì²œì„ ë§ì´ ë°›ì•˜ê³ , ë§ˆì¹¨ ì¶œíŒì‚¬ ì´ë²¤íŠ¸ë¡œ ì°¸ê°€í•´ì„œ ë²ˆì—­ë³¸ë„ ìš´ ì¢‹ê²Œ ì§‘ì— ìˆì—ˆê¸° ë•Œë¬¸ì— ì¤‘ìš”í•œ ë¶€ë¶„ë§Œ ê³¨ë¼ì„œ ì •ë¦¬í•´ë³¸ë‹¤!

ì±…ì€ í¬ê²Œ 3ê°œì˜ Partë¡œ ë‚˜ëˆ„ì–´ì§„ë‹¤. Part 1ì€ 4ê°œì˜ ì¥ìœ¼ë¡œ ë˜ì–´ ìˆê³ , Linear Algebra, Probability and Information Theory, Numerical Computation, Machine Learning Basics ìˆœì„œë¡œ ë˜ì–´ ìˆë‹¤. ê¸°ë³¸ ìˆ˜í•™ ì§€ì‹ê³¼ ML ê°œë…ë“¤ì„ ì„¤ëª…í•œë‹¤. ê·¸ë˜ì„œ í•´ë‹¹ ì¥ë¶€í„° ì •ë¦¬í•´ë³´ê¸°ë¡œ í–ˆë‹¤. ë¬¼ë¡  ì•„ëŠ” ë¶€ë¶„ì€ í‚¤ì›Œë“œë§Œ ì ì–´ë‘ê³  ë„˜ì–´ê°„ë‹¤.

ì¼ë‹¨ ì„ í˜• ëŒ€ìˆ˜ì— ìµìˆ™í•˜ë©´ ì•ˆë´ë„ ë˜ëŠ” ì±•í„°ë¡œ ë³´ì´ì§€ë§Œ ìˆ˜ì—…ì—ì„œ ë“¤ì—ˆë˜ ë‚´ìš©ë“¤ì„ ê°„ë‹¨í•˜ê²Œ ë– ì˜¬ë¦´ ê²¸ ì½ì–´ë³´ê¸°ë¡œ í–ˆë‹¤. ì±…ì„ ì½ëŠ”ë° ì§€ì¥ ì—†ëŠ” ìˆ˜ì¤€ë§Œ ì„¤ëª…í•˜ê¸° ë•Œë¬¸ì— ë” ê³µë¶€í•˜ê³  ì‹¶ë‹¤ë©´, *The Matrix Cookbook* (Petersen & Pedersen, 2006)ì´ë‚˜, Shilov 1997ì„ ì½ì–´ë³´ë¼ê³  í•œë‹¤.

## Scalars, Vectors, Matrices, and Tensors

* Scalars
* Vectors
* Matrices
* Tensors : an array of numbers arranged on a regular grid with a variable number of axes

### broadcasting

ë¨¸ì‹ ëŸ¬ë‹ì—ì„œ ëœ ì—„ë°€í•œ ê°œë…ì„ ëª‡ëª‡ ì‚¬ìš©í•˜ëŠ”ë° ê·¸ ì¤‘ í•˜ë‚˜ê°€ broad castingì´ë‹¤. matrixì™€ vectorë¥¼ ë”í•´ì„œ ë‹¤ë¥¸ matrixê°€ ë‚˜ì˜¤ëŠ” ì—°ì‚°ì´ broadcastingì´ê³ , ì˜ˆë¥¼ ë“¤ì–´ $$\textbf C = \textbf A  + \textbf b $$ë¥¼ $$ C_{i,j} = A_{i,j} + b_j$$ì²˜ëŸ¼ ì—°ì‚°í•˜ëŠ” ê²½ìš°ë¥¼ ë§í•œë‹¤. ì´ ì—°ì‚°ì€ $$b$$ë¥¼ êµ³ì´ ë³µì‚¬í•´ì„œ ìƒˆ matrixë¥¼ ë§Œë“¤ì§€ ì•Šì•„ë„ ë˜ê²Œ í•œë‹¤.

## Multiplying Matrices and Vectors

* standard product : $$\textbf C = \textbf A \textbf B$$
* Hadamard product (element-wise product) : $$\textbf C = \textbf A \odot \textbf B$$

### a system of linear equation

$$\textbf A \textbf x = \textbf b$$

where $$ \textbf A \in \mathbb R^{m \times n} $$, $$\textbf b \in \mathbb R^m$$ and $$\textbf x \in \mathbb R^n $$ ($$x$$ is unknown vector)

## Identity and Inverse Matrices

* Identity matrices : $$I_n \in \mathbb R^{n\times n}$$
* Invese Matrix of $$\textbf A$$ : $$\textbf A ^{-1}$$

## Linear Dependence and Span

ìœ„ì—ì„œ ë‚˜ì˜¨ a system of linear equationì‹ì´ ì•„ë˜ì™€ ê°™ë‹¤.$$\textbf A_{:,i}$$ëŠ” $$\textbf A$$ì˜ $$i$$ë²ˆì§¸ column.

$$\textbf A \textbf x = \sum_i x_i \textbf A_{:,i} = \textbf b$$

ì¦‰, $$\textbf A$$ì˜ columnë“¤ì˜ linear combinationìœ¼ë¡œ ë³´ëŠ” ê²ƒì´ë‹¤.

spanì€ ì£¼ì–´ì§„ ë²¡í„° ì§‘í•©ì—ì„œ linear combinationìœ¼ë¡œ ì–»ì„ ìˆ˜ ìˆëŠ” ì ì˜ ì§‘í•©ì´ë‹¤. ë”°ë¼ì„œ $$\textbf A \textbf x = \textbf b$$ì‹ì„ í–‰ë ¬ $$\textbf A$$ì˜ columnë“¤ì˜ spanì— $$\textbf b$$ê°€ ìˆëŠ”ì§€ì˜ ë¬¸ì œë¡œ ì ‘ê·¼í•  ìˆ˜ ìˆëŠ”ë°, ì´ ê²½ìš° í•´ë‹¹ spanì„ column spaceë¼ í•œë‹¤.

linear independentëŠ” ì£¼ì–´ì§„ ë²¡í„° ì§‘í•©ì—ì„œ ì–´ëŠ í•œ ë²¡í„°ê°€ ë‹¤ë¥¸ ë²¡í„°ì˜ linear combinationìœ¼ë¡œ í‘œí˜„í•  ìˆ˜ ì—†ëŠ” ê²½ìš°ë¥¼ ë§í•œë‹¤. linear dependentëŠ” ê·¸ ë°˜ëŒ€.

square matrixì´ë©´ì„œ $$\textbf A$$ì˜ columnë“¤ì´ linearly independentí•˜ë©´ singular matrixë¼ í•œë‹¤.

## Norm

* $$L^p$$ Norm
$$||x||_p = (\sum_i |x_i|^p)^{\frac 1 p}$$
* $$L^2$$ Norm = Euclidean norm
* ê°€ë” nonzero elementì˜ ê°¯ìˆ˜ë¥¼ ì„¼ ê²ƒì„ $$L^0$$ normì´ë¼ í•˜ëŠ”ë°, ì´ê±´ ì˜ëª»ëœ ìš©ì–´. ê·¸ëƒ¥ $$L^1$$ normìœ¼ë¡œ ëŒ€ì²´í•˜ì.
* max norm
$$||x||_\infty = \max_i |x_i|$$

## Special Kinds of Matrices and Vectors

* diagonal matrix: main diagonal ë¹¼ê³  ë‹¤ 0ì¸ í–‰ë ¬
  * multiplicationì´ ë§¤ìš° íš¨ìœ¨ì 
  * invertingë„ ë§¤ìš° íš¨ìœ¨ì 
* symmetric matrix: $$\textbf A = \textbf A ^\intercal$$
* unit vector
$$||x||_2 = 1$$
* orthogonal vector: $$\textbf x^\intercal \textbf y = 0$$
* orthogonal matrix: $$\textbf A^\intercal \textbf A = \textbf A \textbf A^\intercal = \textbf I$$

## eigen decomposition

ì•„ë˜ëŠ” right eigen vectorë¥¼ êµ¬í•˜ëŠ” ì‹ì¸ë°, leftëŠ” êµ³ì´ ë³„ë¡œ ì•ˆì“´ë‹¤ê³  í•œë‹¤.

$$ \textbf A \textbf v = \lambda \textbf v$$

* eigen value: $$\lambda$$
* eigen vector: $$\textbf v$$
* eigendecompositoin: $$\textbf A = \textbf V diag (\lambda) \textbf V ^{-1}$$
  * ë³´í†µ eigen valueì˜ ë²¡í„°ëŠ” ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ ì •ë ¬í•´ì„œ ì‘ì„±í•œë‹¤ê³  í•¨.
* ì„ì˜ì˜ real symmetric matrixëŠ” ìµœì†Œí•œ í•˜ë‚˜ì˜ eigen decompositionì´ ì¡´ì¬í•œë‹¤.
* eigen valueì˜ ë¶€í˜¸ì— ë”°ë¼ positive definite, positive semidefinite, negative definite, negative semidefiniteë¡œ ë¶€ë¥¸ë‹¤.

## Singular Value Decomposition

singular valueì™€ singular vectorë¡œ decomposeí•˜ëŠ” ê²ƒì´ë‹¤. square matrixê°€ ì•„ë‹ ë•Œ eigen decompositionì„ í•˜ì§€ ëª»í•˜ë‹ˆ ì“´ë‹¤ê³  í•œë‹¤.

$$\textbf A = \textbf U \textbf D \textbf V^\intercal$$

$$\textbf U$$ëŠ” $$m\times m$$ì´ë©´ì„œ orthogonalí•˜ê³  ê·¸ columnë“¤ì´ left singular vectorsì´ë‹¤. $$\textbf D$$ëŠ” diagonal matrixì´ë©´ì„œ $$m \times n$$ì´ë©° main diagonalì— ìˆëŠ” elementë“¤ì´ singular valuesì´ë‹¤. $$\textbf V$$ëŠ” $$n \times n$$ì´ë©´ì„œ orthogonalí•˜ê³  ê·¸ columnë“¤ì„ right singular vectorsë¡œ ë¶€ë¥¸ë‹¤.

## The Moore-Penrose Pseudoinverse

$$\textbf A^{+} = \lim_{a \rightarrow 0} (\textbf  A^\intercal \textbf  A + \alpha \textbf I) ^ {-1} \textbf  A ^\intercal $$

$$\textbf A^{+} = \textbf V \textbf D^+ \textbf U^\intercal$$

ì²«ë²ˆì§¸ê°€ ì •ì˜ì´ê³  ì‹¤ì œë¡œ êµ¬í˜„í•  ë•ŒëŠ” ë‘ë²ˆì§¸ì‹ì„ ë”°ë¥¸ë‹¤ê³  í•œë‹¤. $$\textbf D^+$$ëŠ” 0ì´ ì•„ë‹Œ elementë“¤ì— ì—­ìˆ˜ë¥¼ ì·¨í•˜ê³  transposeí•´ì„œ ì–»ì€ í–‰ë ¬ì´ë‹¤.

## Trace Operator

* ì •ì˜: $$Tr(\textbf A) = \sum_i \textbf A_{i, j}$$
* ì„±ì§ˆ: $$Tr(\textbf A \textbf B \textbf C) = Tr(\textbf B \textbf C \textbf A) = ...$$

## The Determinant

* ê·¸ëƒ¥ $$det (\textbf A)$$
