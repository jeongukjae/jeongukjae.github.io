---
layout: post
title: "ğŸ“• CS224n Lecture 12 Information from parts of words: Subword Models"
tags:
  - nlp
  - cs224n
  - machine learning
---

12ê°•ê¹Œì§€ëŠ” ì €ì €ë²ˆì£¼ì— ë“¤ì—ˆë˜ ê²ƒì´ì§€ë§Œ, ì´ì œ ì •ë¦¬í•˜ë ¤ê³  í•˜ë‹ˆ ì œëŒ€ë¡œ ê¸°ì–µì´ ì•ˆë‚˜ì„œ ë‹¤ì‹œ ë“¤ìœ¼ë©´ì„œ ì •ë¦¬í•œë‹¤.

## A tiny bit of linguistics

* phonetics: sound stream
* phonologyëŠ” phonemesë¡œ ì´ë£¨ì–´ì§„ë‹¤.

í•˜ë‚˜ì˜ ë‹¨ì–´ëŠ” ì—¬ëŸ¬ ê°œì˜ semantic unitìœ¼ë¡œ êµ¬ì„±ëœ ê²½ìš°ê°€ ë§ì€ë°, ì˜ˆë¥¼ ë“¤ì–´ `un- + fortun(e)- + -ate + -ly`ì™€ ê°™ì€ ê²½ìš°ì´ë‹¤. "ê·¸ëŸ¼ ì´ëŸ° ì •ë³´ë¥¼ ëª¨ë¸ì—ì„œ ë” ì´ìš©í•  ìˆ˜ëŠ” ì—†ì„ê¹Œ?" ë¼ëŠ” ìƒê°ì´ subword modelsì˜ ë©”ì¸ ì•„ì´ë””ì–´ì´ë‹¤. (Wickelphones (Rumelhart & McClelland 1986), Microsoftâ€™s DSSM (Huang, He, Gao, Deng, Acero, & Hect 2013))

ê·¸ëŸ¼ ëª¨ë“  ì–¸ì–´ë“¤ì´ ë‹¨ì–´ë¥¼ êµ¬ë¶„ì„ í•´ì£¼ëŠ”ê°€ëŠ” ë˜ ì•„ë‹ˆë‹¤. ì¤‘êµ­ì–´ë¥¼ ì˜ˆë¡œ ë³´ë©´ word segmentationì´ ì—†ë‹¤ê³  í•œë‹¤. (ì´ ë¶€ë¶„ì€ í™•ì‹¤í•˜ì§€ ì•Šì§€ë§Œ, ê°•ì˜ì—ì„œ ë‚˜ì˜¨ ë‚´ìš©ì´ë‹¤) ì¼ë³¸ì–´ë¥¼ ë³´ë”ë¼ê³  ë„ì–´ì“°ê¸°ë¥¼ í•˜ì§€ ì•ŠëŠ”ë‹¤.

word level modelì„ ì‚¬ìš©í•˜ë©´ large, open vocabularyê°€ í•„ìš”í•˜ê¸° ë•Œë¬¸ì— ì°¨ë¼ë¦¬ character level modelì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì€ ì–´ë–¨ê¹Œ?

## Purely character-level models

word embeddingì´ character embeddingìœ¼ë¡œë¶€í„° êµ¬ì„±í•  ìˆ˜ ìˆëŠ” ëª¨ë¸ì„ ë§Œë“ ë‹¤. ë”°ë¼ì„œ ëª¨ë¥´ëŠ” ë‹¨ì–´ë„ embedí•  ìˆ˜ ìˆë‹¤ëŠ” ì¥ì ì´ ìˆë‹¤. ê·¸ë¦¬ê³  ë¹„ìŠ·í•œ ìŠ¤í ë§ì˜ ë‹¨ì–´ëŠ” ë¹„ìŠ·í•œ ì„ë² ë”©ì„ ê°€ì§€ê²Œ ëœë‹¤. ë”°ë¼ì„œ Out of Vocabulary (OOV) Problemë¥¼ í•´ê²°í•˜ê²Œ ëœë‹¤. ê·¸ë¦¬ê³  connected language (ì¤‘êµ­ì–´ê°™ì€) ë“¤ë„ ìì—°ìŠ¤ëŸ½ê²Œ ì²˜ë¦¬í•  ìˆ˜ ìˆê²Œ ëœë‹¤. [^VDCNN]

[^VDCNN]: [Very Deep Convolutional Networks for Text Classification](https://arxiv.org/abs/1606.01781) ì•„ì£¼ ì¢‹ì€ ì˜ˆì‹œ

Purely Character Level NMT Modelì— ê´€ì‹¬ì´ ìˆìœ¼ë©´ ì•„ë˜ ëª©ë¡ì„ ì°¾ì•„ë³´ì

* Vilar et al., 2007
* Neubig et al., 2013
* Junyoung Chung, Kyunghyun Cho, Yoshua Bengio. arXiv 2016
* Wang Ling, Isabel Trancoso, Chris Dyer, Alan Black, arXiv 2015
* Thang Luong, Christopher Manning, ACL 2016
* Marta R. Costa-JussaÌ€, JoseÌ A. R. Fonollosa, ACL 2016

ê·¸ ì´í›„ seq2seqë¥¼ character levelë¡œ ë§Œë“¤ì–´ì„œ í…ŒìŠ¤íŠ¸ë¥¼ í–ˆëŠ”ë°, word level baselineì— ë¹„í•´ ë‚˜ë¦„ ì˜ ë™ì‘í–ˆë‹¤. í•˜ì§€ë§Œ training timeì´ 3ì£¼ë‚˜ ê±¸ë¦¬ëŠ” ë“± ë„ˆë¬´ ëŠë ¸ë‹¤.. (ì°¸ê³ ë¡œ word level modelì´ BLEUê°€ 15.7 ì ì´ì—ˆëŠ”ë°, character level modleì´ 15.9ì •ë„ê°€ ë‚˜ì™”ë‹¤) English-Czech WMT 2015 ê²°ê³¼ì˜€ë‹¤ê³  í•œë‹¤.

ê·¸ ì™¸ì—ë„ [Jason Lee, Kyunghyun Cho, Thomas Hoffmann. 2017](https://arxiv.org/abs/1610.03017)ë„ ì°¸ê³ í•´ë³´ë©´ ì¢‹ì„ ê²ƒ ê°™ë‹¤. decoderë¡œ char-level GRUë¥¼ ì‚¬ìš©í–ˆë‹¤ê³  í•œë‹¤. [Revisiting Character-Based Neural Machine Translation with Capacity and Compression](https://arxiv.org/abs/1808.09943)ë„ ì°¸ê³ í•´ë³´ë¼ê³ ..

## Subword-models: byte pair encoding and friends

ë‘ê°€ì§€ íŠ¸ë Œë“œê°€ ìˆëŠ”ë°, word-level modelê´€ë ¨ëœ ëª¨ë¸[^wp1][^wp2]ì´ë‘ (word pieces) hybrid ë°©ì‹ì„ ì‚¬ìš©í•˜ëŠ” ëª¨ë¸ì´ë‹¤. ì¼ë‹¨ ë©”ì¸ì€ word-levelì´ê³ , character levelì„ ì¶”ê°€ì ìœ¼ë¡œ ì‚¬ìš©í•œë‹¤.[^hybrid1][^hybrid2]

[^wp1]: [Neural Machine Translation of Rare Words with Subword Units](https://arxiv.org/abs/1508.07909) ì°¸ê³ í•´ë³´ì
[^wp2]: [A Character-Level Decoder without Explicit Segmentation for Neural Machine Translation](https://arxiv.org/abs/1603.06147) ì°¸ê³ í•´ë³´ì

[^hybrid1]: [Character-based Neural Machine Translation](https://arxiv.org/abs/1603.00810)
[^hybrid2]: [Achieving Open Vocabulary Neural Machine Translation with Hybrid Word-Character Models](https://arxiv.org/abs/1604.00788)

### Byte Pair Encoding

Byte Pair Encodingì€ ì›ë˜ Compression Algorithmì´ë‹¤. most frequent byte pairë¥¼ ë³‘í•©í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ ì •ë„ë¡œ ë³¼ ìˆ˜ ìˆëŠ”ë°, [Neural Machine Translation of Rare Words with Subword Units](https://arxiv.org/abs/1508.07909), [GitHub rsennrich/subword-nmt](https://github.com/rsennrich/subword-nmt), [GitHub EdinburghNLP/nematus](https://github.com/EdinburghNLP/nematus)ë¥¼ ì°¸ê³ í•˜ë¼ê³  í•œë‹¤.

### Wordpiece/SentencePiece model

wordpieceëŠ” wordì•ˆì—ì„œ tokenizingí•˜ëŠ” ëª¨ë¸. sentencepieceëŠ” raw textì—ì„œ ë™ì‘í•˜ëŠ” ëª¨ë¸ì¸ë°, whitespaceê°€ special tokenì„ ê°€ì§€ê²Œ í•˜ê³ , groupingí•˜ëŠ” ë“±ì˜ ì²˜ë¦¬ë¥¼ í•´ì£¼ëŠ” ëª¨ë¸..?ì¸ê°€ ì‹¶ë‹¤.

* [GitHub google/sentencepiece](https://github.com/google/sentencepiece)
* [Subword Regularization: Improving Neural Network Translation Models with Multiple Subword Candidates](https://arxiv.org/abs/1804.10959)

Bertê°€ wordpiece ëª¨ë¸ì˜ variantë¥¼ ì‚¬ìš©í•œë‹¤. ë‹¤ë¥¸ ë‹¨ì–´ë“¤ì„ wordpieceë¡œ ë§Œë“¤ì–´ë‚¼ ìˆ˜ ìˆê¸° ë•Œë¬¸ì— ì´ì ì´ ìˆë‹¤ê³ .

---

ê·¸ ì™¸ì—ë„ subword modelsë¡œ ë³¼ ìˆ˜ ìˆëŠ” ëª¨ë¸ë“¤ ì¤‘ì— word embeddingì„ ë§Œë“¤ì–´ë‚´ê¸° ìœ„í•´ convolutionì„ characterë“¤ì— ì‹œí‚¤ëŠ” ëª¨ë¸ë“¤ë„ ìˆê³ , word representationì„ ìœ„í•´ character based LSTMì„ ì ìš©í•œ ëª¨ë¸ë„ ìˆë‹¤ê³  í•œë‹¤.

Highway Networkë„ ë‚˜ì¤‘ì— ì‚´í´ë³´ì.[^HN]

[^HN]: [Highway Networks](https://arxiv.org/abs/1505.00387)

## Hybrid character and word level models

Hybrid NMTë¼ê³ , ê±°ì˜ word levelì—ì„œ ë²ˆì—­í•˜ê³ , í•„ìš”í•  ê²½ìš° char-levelì„ ê°€ëŠ” ëª¨ë¸ë„ ìˆë‹¤ê³  í•œë‹¤.[^hybrid2]

## FastText

[A Joint Model for Word Embedding and Word Morphology](https://arxiv.org/abs/1606.02601)ì„ ì‚´í´ë³´ë©´ ê¸°ë³¸ì ìœ¼ë¡œ word embeddingì„ í•˜ê¸° ìœ„í•œ ëª¨ë¸ì´ì§€ë§Œ word morphologyë„ ì‚´í´ë³¼ ìˆ˜ ìˆëŠ” ëª¨ë¸ì´ë¼ê³  í•œë‹¤.

[Enriching Word Vectors with Subword Information](https://arxiv.org/abs/1607.04606)ì€ fastTextì˜ ë…¼ë¬¸ì¸ë°, ì‹¤ì œ ì½”ë“œë‚˜ ì‚¬ìš©ì€ [https://fasttext.cc](https://fasttext.cc) ë¥¼ ì‚´í´ë³´ì
